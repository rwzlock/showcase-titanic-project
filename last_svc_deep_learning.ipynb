{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "# %matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_cleaned_v2 = pd.read_csv('AG_train-test_v2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_data_cleaned_v2.drop('Survived', axis = 1)\n",
    "y = train_data_cleaned_v2['Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pclass  Sex   Age  SibSp  Parch  Fare  Embarked\n",
       "0       3    0  22.0      1      0     0         0\n",
       "1       1    1  38.0      1      0     0         1\n",
       "2       3    1  26.0      0      0     0         0\n",
       "3       1    1  35.0      1      0     0         0\n",
       "4       3    0  35.0      0      0     0         0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.drop('Unnamed: 0', axis = 1, inplace=True)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Support vector machine linear classifier\n",
    "from sklearn.svm import SVC\n",
    "model = SVC(kernel='linear')\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Acc: 0.791\n"
     ]
    }
   ],
   "source": [
    "# Model Accuracy\n",
    "print('Test Acc: %.3f' % model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Create a StandardScater model and fit it to the training data\n",
    "X_scaler = StandardScaler().fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the training and testing data using the X_scaler\n",
    "\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "# One-hot encoding\n",
    "y_train_categorical = to_categorical(y_train)\n",
    "y_test_categorical = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first, create a normal neural network with 2 inputs, 6 hidden nodes, and 2 outputs\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(units=6, activation='relu', input_dim=7))\n",
    "model.add(Dense(units=2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 6)                 48        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 14        \n",
      "=================================================================\n",
      "Total params: 62\n",
      "Trainable params: 62\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      " - 0s - loss: 1.1874 - acc: 0.3472\n",
      "Epoch 2/100\n",
      " - 0s - loss: 1.1309 - acc: 0.3472\n",
      "Epoch 3/100\n",
      " - 0s - loss: 1.0822 - acc: 0.3509\n",
      "Epoch 4/100\n",
      " - 0s - loss: 1.0392 - acc: 0.3528\n",
      "Epoch 5/100\n",
      " - 0s - loss: 0.9998 - acc: 0.3528\n",
      "Epoch 6/100\n",
      " - 0s - loss: 0.9671 - acc: 0.3472\n",
      "Epoch 7/100\n",
      " - 0s - loss: 0.9358 - acc: 0.3623\n",
      "Epoch 8/100\n",
      " - 0s - loss: 0.9104 - acc: 0.3774\n",
      "Epoch 9/100\n",
      " - 0s - loss: 0.8858 - acc: 0.4000\n",
      "Epoch 10/100\n",
      " - 0s - loss: 0.8645 - acc: 0.4189\n",
      "Epoch 11/100\n",
      " - 0s - loss: 0.8456 - acc: 0.4358\n",
      "Epoch 12/100\n",
      " - 0s - loss: 0.8268 - acc: 0.4491\n",
      "Epoch 13/100\n",
      " - 0s - loss: 0.8111 - acc: 0.4962\n",
      "Epoch 14/100\n",
      " - 0s - loss: 0.7961 - acc: 0.5434\n",
      "Epoch 15/100\n",
      " - 0s - loss: 0.7813 - acc: 0.5585\n",
      "Epoch 16/100\n",
      " - 0s - loss: 0.7676 - acc: 0.5660\n",
      "Epoch 17/100\n",
      " - 0s - loss: 0.7546 - acc: 0.5774\n",
      "Epoch 18/100\n",
      " - 0s - loss: 0.7420 - acc: 0.5887\n",
      "Epoch 19/100\n",
      " - 0s - loss: 0.7299 - acc: 0.5906\n",
      "Epoch 20/100\n",
      " - 0s - loss: 0.7172 - acc: 0.5887\n",
      "Epoch 21/100\n",
      " - 0s - loss: 0.7044 - acc: 0.6038\n",
      "Epoch 22/100\n",
      " - 0s - loss: 0.6922 - acc: 0.6113\n",
      "Epoch 23/100\n",
      " - 0s - loss: 0.6796 - acc: 0.6283\n",
      "Epoch 24/100\n",
      " - 0s - loss: 0.6666 - acc: 0.6415\n",
      "Epoch 25/100\n",
      " - 0s - loss: 0.6538 - acc: 0.6472\n",
      "Epoch 26/100\n",
      " - 0s - loss: 0.6409 - acc: 0.6566\n",
      "Epoch 27/100\n",
      " - 0s - loss: 0.6282 - acc: 0.6925\n",
      "Epoch 28/100\n",
      " - 0s - loss: 0.6156 - acc: 0.7094\n",
      "Epoch 29/100\n",
      " - 0s - loss: 0.6036 - acc: 0.7321\n",
      "Epoch 30/100\n",
      " - 0s - loss: 0.5923 - acc: 0.7491\n",
      "Epoch 31/100\n",
      " - 0s - loss: 0.5809 - acc: 0.7642\n",
      "Epoch 32/100\n",
      " - 0s - loss: 0.5705 - acc: 0.7623\n",
      "Epoch 33/100\n",
      " - 0s - loss: 0.5606 - acc: 0.7679\n",
      "Epoch 34/100\n",
      " - 0s - loss: 0.5510 - acc: 0.7774\n",
      "Epoch 35/100\n",
      " - 0s - loss: 0.5421 - acc: 0.7792\n",
      "Epoch 36/100\n",
      " - 0s - loss: 0.5346 - acc: 0.7811\n",
      "Epoch 37/100\n",
      " - 0s - loss: 0.5269 - acc: 0.7811\n",
      "Epoch 38/100\n",
      " - 0s - loss: 0.5203 - acc: 0.7830\n",
      "Epoch 39/100\n",
      " - 0s - loss: 0.5137 - acc: 0.7830\n",
      "Epoch 40/100\n",
      " - 0s - loss: 0.5083 - acc: 0.7868\n",
      "Epoch 41/100\n",
      " - 0s - loss: 0.5028 - acc: 0.7868\n",
      "Epoch 42/100\n",
      " - 0s - loss: 0.4981 - acc: 0.7868\n",
      "Epoch 43/100\n",
      " - 0s - loss: 0.4942 - acc: 0.7906\n",
      "Epoch 44/100\n",
      " - 0s - loss: 0.4900 - acc: 0.7887\n",
      "Epoch 45/100\n",
      " - 0s - loss: 0.4866 - acc: 0.7887\n",
      "Epoch 46/100\n",
      " - 0s - loss: 0.4835 - acc: 0.7906\n",
      "Epoch 47/100\n",
      " - 0s - loss: 0.4805 - acc: 0.7887\n",
      "Epoch 48/100\n",
      " - 0s - loss: 0.4781 - acc: 0.7906\n",
      "Epoch 49/100\n",
      " - 0s - loss: 0.4758 - acc: 0.7925\n",
      "Epoch 50/100\n",
      " - 0s - loss: 0.4740 - acc: 0.7925\n",
      "Epoch 51/100\n",
      " - 0s - loss: 0.4717 - acc: 0.7925\n",
      "Epoch 52/100\n",
      " - 0s - loss: 0.4699 - acc: 0.7943\n",
      "Epoch 53/100\n",
      " - 0s - loss: 0.4683 - acc: 0.7943\n",
      "Epoch 54/100\n",
      " - 0s - loss: 0.4672 - acc: 0.7981\n",
      "Epoch 55/100\n",
      " - 0s - loss: 0.4657 - acc: 0.7981\n",
      "Epoch 56/100\n",
      " - 0s - loss: 0.4645 - acc: 0.7981\n",
      "Epoch 57/100\n",
      " - 0s - loss: 0.4632 - acc: 0.7981\n",
      "Epoch 58/100\n",
      " - 0s - loss: 0.4621 - acc: 0.7981\n",
      "Epoch 59/100\n",
      " - 0s - loss: 0.4611 - acc: 0.7981\n",
      "Epoch 60/100\n",
      " - 0s - loss: 0.4602 - acc: 0.7981\n",
      "Epoch 61/100\n",
      " - 0s - loss: 0.4589 - acc: 0.7981\n",
      "Epoch 62/100\n",
      " - 0s - loss: 0.4582 - acc: 0.7981\n",
      "Epoch 63/100\n",
      " - 0s - loss: 0.4572 - acc: 0.7981\n",
      "Epoch 64/100\n",
      " - 0s - loss: 0.4565 - acc: 0.7981\n",
      "Epoch 65/100\n",
      " - 0s - loss: 0.4556 - acc: 0.7981\n",
      "Epoch 66/100\n",
      " - 0s - loss: 0.4547 - acc: 0.7981\n",
      "Epoch 67/100\n",
      " - 0s - loss: 0.4540 - acc: 0.7981\n",
      "Epoch 68/100\n",
      " - 0s - loss: 0.4533 - acc: 0.7981\n",
      "Epoch 69/100\n",
      " - 0s - loss: 0.4525 - acc: 0.7981\n",
      "Epoch 70/100\n",
      " - 0s - loss: 0.4518 - acc: 0.7962\n",
      "Epoch 71/100\n",
      " - 0s - loss: 0.4512 - acc: 0.7962\n",
      "Epoch 72/100\n",
      " - 0s - loss: 0.4505 - acc: 0.7962\n",
      "Epoch 73/100\n",
      " - 0s - loss: 0.4498 - acc: 0.7962\n",
      "Epoch 74/100\n",
      " - 0s - loss: 0.4492 - acc: 0.7962\n",
      "Epoch 75/100\n",
      " - 0s - loss: 0.4486 - acc: 0.7962\n",
      "Epoch 76/100\n",
      " - 0s - loss: 0.4480 - acc: 0.7962\n",
      "Epoch 77/100\n",
      " - 0s - loss: 0.4474 - acc: 0.7962\n",
      "Epoch 78/100\n",
      " - 0s - loss: 0.4467 - acc: 0.7962\n",
      "Epoch 79/100\n",
      " - 0s - loss: 0.4462 - acc: 0.7962\n",
      "Epoch 80/100\n",
      " - 0s - loss: 0.4456 - acc: 0.7962\n",
      "Epoch 81/100\n",
      " - 0s - loss: 0.4451 - acc: 0.7962\n",
      "Epoch 82/100\n",
      " - 0s - loss: 0.4446 - acc: 0.7981\n",
      "Epoch 83/100\n",
      " - 0s - loss: 0.4442 - acc: 0.7981\n",
      "Epoch 84/100\n",
      " - 0s - loss: 0.4435 - acc: 0.7962\n",
      "Epoch 85/100\n",
      " - 0s - loss: 0.4430 - acc: 0.7981\n",
      "Epoch 86/100\n",
      " - 0s - loss: 0.4426 - acc: 0.7981\n",
      "Epoch 87/100\n",
      " - 0s - loss: 0.4421 - acc: 0.8000\n",
      "Epoch 88/100\n",
      " - 0s - loss: 0.4415 - acc: 0.8000\n",
      "Epoch 89/100\n",
      " - 0s - loss: 0.4411 - acc: 0.8038\n",
      "Epoch 90/100\n",
      " - 0s - loss: 0.4408 - acc: 0.8019\n",
      "Epoch 91/100\n",
      " - 0s - loss: 0.4404 - acc: 0.8000\n",
      "Epoch 92/100\n",
      " - 0s - loss: 0.4400 - acc: 0.8019\n",
      "Epoch 93/100\n",
      " - 0s - loss: 0.4398 - acc: 0.8000\n",
      "Epoch 94/100\n",
      " - 0s - loss: 0.4392 - acc: 0.8038\n",
      "Epoch 95/100\n",
      " - 0s - loss: 0.4389 - acc: 0.8019\n",
      "Epoch 96/100\n",
      " - 0s - loss: 0.4385 - acc: 0.8019\n",
      "Epoch 97/100\n",
      " - 0s - loss: 0.4381 - acc: 0.8038\n",
      "Epoch 98/100\n",
      " - 0s - loss: 0.4379 - acc: 0.8075\n",
      "Epoch 99/100\n",
      " - 0s - loss: 0.4374 - acc: 0.8038\n",
      "Epoch 100/100\n",
      " - 0s - loss: 0.4373 - acc: 0.8057\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1cf299fc320>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model to the training data\n",
    "model.fit(\n",
    "    X_train_scaled,\n",
    "    y_train_categorical,\n",
    "    epochs=100,\n",
    "    shuffle=True,\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "deep_model = Sequential()\n",
    "deep_model.add(Dense(units=6, activation='relu', input_dim=7))\n",
    "deep_model.add(Dense(units=6, activation='relu'))\n",
    "deep_model.add(Dense(units=6, activation='relu'))\n",
    "\n",
    "deep_model.add(Dense(units=2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 6)                 48        \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 6)                 42        \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 6)                 42        \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 2)                 14        \n",
      "=================================================================\n",
      "Total params: 146\n",
      "Trainable params: 146\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "deep_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      " - 1s - loss: 0.6793 - acc: 0.5774\n",
      "Epoch 2/100\n",
      " - 0s - loss: 0.6612 - acc: 0.6491\n",
      "Epoch 3/100\n",
      " - 0s - loss: 0.6472 - acc: 0.6887\n",
      "Epoch 4/100\n",
      " - 0s - loss: 0.6345 - acc: 0.6981\n",
      "Epoch 5/100\n",
      " - 0s - loss: 0.6226 - acc: 0.7094\n",
      "Epoch 6/100\n",
      " - 0s - loss: 0.6113 - acc: 0.7170\n",
      "Epoch 7/100\n",
      " - 0s - loss: 0.6006 - acc: 0.7264\n",
      "Epoch 8/100\n",
      " - 0s - loss: 0.5891 - acc: 0.7321\n",
      "Epoch 9/100\n",
      " - 0s - loss: 0.5792 - acc: 0.7340\n",
      "Epoch 10/100\n",
      " - 0s - loss: 0.5684 - acc: 0.7453\n",
      "Epoch 11/100\n",
      " - 0s - loss: 0.5585 - acc: 0.7453\n",
      "Epoch 12/100\n",
      " - 0s - loss: 0.5489 - acc: 0.7472\n",
      "Epoch 13/100\n",
      " - 0s - loss: 0.5401 - acc: 0.7547\n",
      "Epoch 14/100\n",
      " - 0s - loss: 0.5310 - acc: 0.7642\n",
      "Epoch 15/100\n",
      " - 0s - loss: 0.5227 - acc: 0.7679\n",
      "Epoch 16/100\n",
      " - 0s - loss: 0.5137 - acc: 0.7755\n",
      "Epoch 17/100\n",
      " - 0s - loss: 0.5055 - acc: 0.7811\n",
      "Epoch 18/100\n",
      " - 0s - loss: 0.4989 - acc: 0.7849\n",
      "Epoch 19/100\n",
      " - 0s - loss: 0.4921 - acc: 0.7868\n",
      "Epoch 20/100\n",
      " - 0s - loss: 0.4860 - acc: 0.7868\n",
      "Epoch 21/100\n",
      " - 0s - loss: 0.4810 - acc: 0.7887\n",
      "Epoch 22/100\n",
      " - 0s - loss: 0.4762 - acc: 0.7868\n",
      "Epoch 23/100\n",
      " - 0s - loss: 0.4718 - acc: 0.7887\n",
      "Epoch 24/100\n",
      " - 0s - loss: 0.4684 - acc: 0.7868\n",
      "Epoch 25/100\n",
      " - 0s - loss: 0.4633 - acc: 0.7906\n",
      "Epoch 26/100\n",
      " - 0s - loss: 0.4600 - acc: 0.7925\n",
      "Epoch 27/100\n",
      " - 0s - loss: 0.4578 - acc: 0.7906\n",
      "Epoch 28/100\n",
      " - 0s - loss: 0.4546 - acc: 0.7962\n",
      "Epoch 29/100\n",
      " - 0s - loss: 0.4530 - acc: 0.7943\n",
      "Epoch 30/100\n",
      " - 0s - loss: 0.4508 - acc: 0.7906\n",
      "Epoch 31/100\n",
      " - 0s - loss: 0.4477 - acc: 0.8000\n",
      "Epoch 32/100\n",
      " - 0s - loss: 0.4460 - acc: 0.7981\n",
      "Epoch 33/100\n",
      " - 0s - loss: 0.4444 - acc: 0.7981\n",
      "Epoch 34/100\n",
      " - 0s - loss: 0.4433 - acc: 0.7962\n",
      "Epoch 35/100\n",
      " - 0s - loss: 0.4421 - acc: 0.7981\n",
      "Epoch 36/100\n",
      " - 0s - loss: 0.4409 - acc: 0.8019\n",
      "Epoch 37/100\n",
      " - 0s - loss: 0.4402 - acc: 0.7981\n",
      "Epoch 38/100\n",
      " - 0s - loss: 0.4388 - acc: 0.8019\n",
      "Epoch 39/100\n",
      " - 0s - loss: 0.4380 - acc: 0.8057\n",
      "Epoch 40/100\n",
      " - 0s - loss: 0.4367 - acc: 0.8038\n",
      "Epoch 41/100\n",
      " - 0s - loss: 0.4358 - acc: 0.8057\n",
      "Epoch 42/100\n",
      " - 0s - loss: 0.4349 - acc: 0.8075\n",
      "Epoch 43/100\n",
      " - 0s - loss: 0.4341 - acc: 0.8057\n",
      "Epoch 44/100\n",
      " - 0s - loss: 0.4335 - acc: 0.8057\n",
      "Epoch 45/100\n",
      " - 0s - loss: 0.4327 - acc: 0.8057\n",
      "Epoch 46/100\n",
      " - 0s - loss: 0.4328 - acc: 0.8113\n",
      "Epoch 47/100\n",
      " - 0s - loss: 0.4318 - acc: 0.8057\n",
      "Epoch 48/100\n",
      " - 0s - loss: 0.4305 - acc: 0.8113\n",
      "Epoch 49/100\n",
      " - 0s - loss: 0.4300 - acc: 0.8075\n",
      "Epoch 50/100\n",
      " - 0s - loss: 0.4296 - acc: 0.8132\n",
      "Epoch 51/100\n",
      " - 0s - loss: 0.4300 - acc: 0.8094\n",
      "Epoch 52/100\n",
      " - 0s - loss: 0.4292 - acc: 0.8113\n",
      "Epoch 53/100\n",
      " - 0s - loss: 0.4289 - acc: 0.8132\n",
      "Epoch 54/100\n",
      " - 0s - loss: 0.4273 - acc: 0.8113\n",
      "Epoch 55/100\n",
      " - 0s - loss: 0.4275 - acc: 0.8113\n",
      "Epoch 56/100\n",
      " - 0s - loss: 0.4265 - acc: 0.8094\n",
      "Epoch 57/100\n",
      " - 0s - loss: 0.4261 - acc: 0.8132\n",
      "Epoch 58/100\n",
      " - 0s - loss: 0.4256 - acc: 0.8132\n",
      "Epoch 59/100\n",
      " - 0s - loss: 0.4263 - acc: 0.8094\n",
      "Epoch 60/100\n",
      " - 0s - loss: 0.4248 - acc: 0.8075\n",
      "Epoch 61/100\n",
      " - 0s - loss: 0.4245 - acc: 0.8075\n",
      "Epoch 62/100\n",
      " - 0s - loss: 0.4237 - acc: 0.8094\n",
      "Epoch 63/100\n",
      " - 0s - loss: 0.4236 - acc: 0.8094\n",
      "Epoch 64/100\n",
      " - 0s - loss: 0.4229 - acc: 0.8094\n",
      "Epoch 65/100\n",
      " - 0s - loss: 0.4226 - acc: 0.8113\n",
      "Epoch 66/100\n",
      " - 0s - loss: 0.4223 - acc: 0.8094\n",
      "Epoch 67/100\n",
      " - 0s - loss: 0.4220 - acc: 0.8113\n",
      "Epoch 68/100\n",
      " - 0s - loss: 0.4218 - acc: 0.8094\n",
      "Epoch 69/100\n",
      " - 0s - loss: 0.4217 - acc: 0.8132\n",
      "Epoch 70/100\n",
      " - 0s - loss: 0.4215 - acc: 0.8151\n",
      "Epoch 71/100\n",
      " - 0s - loss: 0.4213 - acc: 0.8132\n",
      "Epoch 72/100\n",
      " - 0s - loss: 0.4209 - acc: 0.8132\n",
      "Epoch 73/100\n",
      " - 0s - loss: 0.4208 - acc: 0.8151\n",
      "Epoch 74/100\n",
      " - 0s - loss: 0.4195 - acc: 0.8170\n",
      "Epoch 75/100\n",
      " - 0s - loss: 0.4202 - acc: 0.8170\n",
      "Epoch 76/100\n",
      " - 0s - loss: 0.4192 - acc: 0.8094\n",
      "Epoch 77/100\n",
      " - 0s - loss: 0.4189 - acc: 0.8113\n",
      "Epoch 78/100\n",
      " - 0s - loss: 0.4186 - acc: 0.8132\n",
      "Epoch 79/100\n",
      " - 0s - loss: 0.4181 - acc: 0.8132\n",
      "Epoch 80/100\n",
      " - 0s - loss: 0.4182 - acc: 0.8094\n",
      "Epoch 81/100\n",
      " - 0s - loss: 0.4173 - acc: 0.8151\n",
      "Epoch 82/100\n",
      " - 0s - loss: 0.4170 - acc: 0.8113\n",
      "Epoch 83/100\n",
      " - 0s - loss: 0.4172 - acc: 0.8170\n",
      "Epoch 84/100\n",
      " - 0s - loss: 0.4184 - acc: 0.8075\n",
      "Epoch 85/100\n",
      " - 0s - loss: 0.4159 - acc: 0.8113\n",
      "Epoch 86/100\n",
      " - 0s - loss: 0.4162 - acc: 0.8113\n",
      "Epoch 87/100\n",
      " - 0s - loss: 0.4158 - acc: 0.8170\n",
      "Epoch 88/100\n",
      " - 0s - loss: 0.4154 - acc: 0.8151\n",
      "Epoch 89/100\n",
      " - 0s - loss: 0.4152 - acc: 0.8132\n",
      "Epoch 90/100\n",
      " - 0s - loss: 0.4152 - acc: 0.8189\n",
      "Epoch 91/100\n",
      " - 0s - loss: 0.4149 - acc: 0.8151\n",
      "Epoch 92/100\n",
      " - 0s - loss: 0.4145 - acc: 0.8170\n",
      "Epoch 93/100\n",
      " - 0s - loss: 0.4147 - acc: 0.8170\n",
      "Epoch 94/100\n",
      " - 0s - loss: 0.4141 - acc: 0.8170\n",
      "Epoch 95/100\n",
      " - 0s - loss: 0.4138 - acc: 0.8170\n",
      "Epoch 96/100\n",
      " - 0s - loss: 0.4131 - acc: 0.8189\n",
      "Epoch 97/100\n",
      " - 0s - loss: 0.4138 - acc: 0.8151\n",
      "Epoch 98/100\n",
      " - 0s - loss: 0.4128 - acc: 0.8151\n",
      "Epoch 99/100\n",
      " - 0s - loss: 0.4129 - acc: 0.8113\n",
      "Epoch 100/100\n",
      " - 0s - loss: 0.4128 - acc: 0.8189\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1cf29dc2da0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deep_model.compile(optimizer='adam',\n",
    "                   loss='categorical_crossentropy',\n",
    "                   metrics=['accuracy'])\n",
    "\n",
    "deep_model.fit(\n",
    "    X_train_scaled,\n",
    "    y_train_categorical,\n",
    "    epochs=100,\n",
    "    shuffle=True,\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal Neural Network - Loss: 0.43087613649960965, Accuracy: 0.7909604536611482\n"
     ]
    }
   ],
   "source": [
    "model_loss, model_accuracy = model.evaluate(\n",
    "    X_test_scaled, y_test_categorical, verbose=2)\n",
    "print(\n",
    "    f\"Normal Neural Network - Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep Neural Network - Loss: 0.43587079661040656, Accuracy: 0.8305084755865194\n"
     ]
    }
   ],
   "source": [
    "model_loss, model_accuracy = deep_model.evaluate(\n",
    "    X_test_scaled, y_test_categorical, verbose=2)\n",
    "print(f\"Deep Neural Network - Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
